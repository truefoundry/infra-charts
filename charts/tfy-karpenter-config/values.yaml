## @section Cluster configurations
##
cluster:
  ## @param cluster.name Name of the EKS cluster
  ##
  name: ""
  ## @param cluster.endpoint Endpoint of the EKS cluster
  ##
  endpoint: ""

## @section Karpenter configurations
##
karpenter:
  ## @param karpenter.instanceProfile Instance profile of the karpenter
  ##
  instanceProfile: ""

  ##
  # default provisioner for non-GPU workloads
  defaultProvisionerSpec:
    # nodes should consolidate to fit in the right instance size
    consolidation:
      ## @param karpenter.defaultProvisionerSpec.consolidation.enabled Enable consolidation for default provisioner
      ##
      enabled: true

    ## @extra karpenter.defaultProvisionerSpec.ttlSecondsAfterEmpty Seconds after which node should be deleted once it is empty. Either one of consolidation or ttlSecondsAfterEmpty should be used
    ## 
    # ttlSecondsAfterEmpty: 30

    ## @skip karpenter.defaultProvisionerSpec.requirements
    requirements:
    - key: karpenter.sh/capacity-type
      operator: In
      values: ["spot"]
    - key: "topology.kubernetes.io/zone"
      operator: In
      values: ["eu-west-1a", "eu-west-1b", "eu-west-1c"]
    - key: kubernetes.io/arch
      operator: In
      values: ["amd64"]
    - key: karpenter.k8s.aws/instance-family
      operator: NotIn
      values: ["t3", "t2", "t3a", "p2", "p3", "p4d", "p4de", "p5", "g4dn", "g5", "g4ad", "inf1", "inf2", "trn1", "trn1n"]
    - key: karpenter.k8s.aws/instance-size
      operator: NotIn
      values: ["nano", "micro", "metal"]

    ## @param karpenter.defaultProvisionerSpec.providerRef.name AWS node template name for default provisioner
    ##
    providerRef:
      name: default

  ## provisioner for GPU workloads
  gpuProvisionerSpec:
    ## @param karpenter.gpuProvisionerSpec.enabled Enable GPU provisioner for GPU nodes
    ##
    enabled: false

    ## @param karpenter.gpuProvisionerSpec.consolidation.enabled Enable consolidation for GPU provisioner
    ##
    consolidation:
      enabled: true

    ## @param karpenter.gpuProvisionerSpec.ttlSecondsAfterEmpty Seconds after which node should be deleted once it is empty. Either one of consolidation or ttlSecondsAfterEmpty should be used
    ## 
    ttlSecondsAfterEmpty: 300

    ## @param karpenter.gpuProvisionerSpec.capacityTypes Capacity types for GPU provisioner
    ##    
    capacityTypes:
    - spot
    - on-demand
    ## @param karpenter.gpuProvisionerSpec.zones Zones to launch instances for GPU provisioner
    ## 
    zones: []
    ## @param karpenter.gpuProvisionerSpec.instanceFamilies Instance families to launch instances for GPU provisioner
    ## 
    instanceFamilies:
    - p2
    - p3
    - g4dn
    - g5
    - p4d
    - p4de
    ## @param karpenter.gpuProvisionerSpec.instanceSizes.notAllowed Instance Sizes that are not allowed to launch instances for GPU provisioner
    ##
    instanceSizes:
      notAllowed:
      - nano
      - micro
      - metal
    ## @param karpenter.gpuProvisionerSpec.providerRefName Name of AWS node template to be used for GPU provisioner
    ##
    providerRefName: gpu-default

  ## Provisioner for Control plane workloads
  controlPlaneProvisioner:
    ## @param karpenter.controlPlaneProvisioner.enabled Enable control plane provisioner for control plane workloads
    ##
    enabled: false

    ## @param karpenter.controlPlaneProvisioner.consolidation.enabled Enable consolidation for control plane provisioner
    ##
    consolidation:
      enabled: true

    ## @param karpenter.controlPlaneProvisioner.ttlSecondsAfterEmpty Time (in seconds) after which node will be drained. Either one of consolidation or ttlSecondsAfterEmpty can be used
    ##
    ttlSecondsAfterEmpty: 30

    ## @param karpenter.controlPlaneProvisioner.capacityTypes Capacity types of control plane provisioner
    ## 
    capacityTypes:
    - spot
    - on-demand

    ## @param karpenter.controlPlaneProvisioner.zones Zones to launch instances for control plane workloads
    ##
    zones: []

    instanceFamilies:
      ## @param karpenter.controlPlaneProvisioner.instanceFamilies.allowed Allowed instance families for control plane workloads
      ##    
      allowed: []

      ## @param karpenter.controlPlaneProvisioner.instanceFamilies.notAllowed Not allowed instance families for control plane workloads
      ##      
      notAllowed: ["t3", "t2", "t3a", "p2", "p3", "p4d", "p4de", "g4dn", "g5", "g4ad", "inf1", "inf2", "trn1", "trn1n", "c1", "cc1", "cc2", "cg1", "cg2", "cr1", "g1", "g2", "hi1", "hs1", "m1", "m2", "m3"]

    instanceSizes:
      ## @param karpenter.controlPlaneProvisioner.instanceSizes.allowed Allowed instance sizes for control plane workloads
      ##  
      allowed: []

      ## @param karpenter.controlPlaneProvisioner.instanceSizes.notAllowed Not allowed instance sizes for control plane workloads
      ## 
      notAllowed: ["nano", "12xlarge", "16xlarge", "24xlarge", "32xlarge", "metal"]

    ## @param karpenter.controlPlaneProvisioner.providerRefName Name of AWS node template to be used for control plane provisioner
    ##
    providerRefName: default

    ## @param karpenter.controlPlaneProvisioner.taints Taints to be applied on the control plane provisioner nodes
    ##
    taints: {}

    ## @param karpenter.controlPlaneProvisioner.labels Labels to be applied on the control plane provisioner nodes
    ##
    labels: {}

  ## control plane node template
  ## control plane provisioner by default will use default node template
  ## if needed we can supply a different node template for control plane provisioner as well
  controlPlaneNodeTemplate:
    ## @param karpenter.controlPlaneNodeTemplate.enabled Size for the root volume attached to node
    enabled: true
    ## @param karpenter.controlPlaneNodeTemplate.enabled Size for the root volume attached to node
    name: controlplane-node-template
    ## @param karpenter.controlPlaneNodeTemplate.rootVolumeSize Size for the root volume attached to node
    rootVolumeSize: 100Gi
    ## @param karpenter.controlPlaneNodeTemplate.extraTags Additional tags for the node template.
    extraTags:
      cp: true
    ## @param karpenter.controlPlaneNodeTemplate.amiFamily AMI family to use for node template
    amiFamily: "Bottlerocket"
    ## @skip karpenter.controlPlaneNodeTemplate.userData
    # Set this to "" to disable this injection
    userData: ""

  ## Default Node Template Config
  defaultNodeTemplate:
    ## @param karpenter.defaultNodeTemplate.rootVolumeSize Size for the root volume attached to node
    rootVolumeSize: 100Gi
    ## @param karpenter.defaultNodeTemplate.extraTags Additional tags for the node template.
    extraTags: {}
    ## @param karpenter.defaultNodeTemplate.amiFamily AMI family to use for node template
    amiFamily: "AL2"
    ## @skip karpenter.defaultNodeTemplate.userData
    # Set this to "" to disable this injection
    userData: ""

  ## Defautl GPU Node Template Config
  gpuDefaultNodeTemplate:
    ## @param karpenter.gpuDefaultNodeTemplate.rootVolumeSize Size for the root volume attached to node
    rootVolumeSize: 100Gi
    ## @param karpenter.gpuDefaultNodeTemplate.extraTags Additional tags for the gpu node template.
    extraTags: {}
    ## @param karpenter.gpuDefaultNodeTemplate.amiFamily AMI family to use for node template
    amiFamily: "AL2"
    ## @skip karpenter.gpuDefaultNodeTemplate.userData
    # Set this to "" to disable this injection
    userData: |
      #!/bin/bash

      set -ex

      version_lte() {
          printf '%s\n' "$1" "$2" | sort -C -V
      }

      version_lt() {
          ! version_lte "$2" "$1"
      }

      CONTAINERD_VERSION_OUTPUT="$(containerd --version)"
      IFS=" " read -a  CONTAINERD_VERSION_STRING <<< "${CONTAINERD_VERSION_OUTPUT}"
      CONTAINERD_VERSION=${CONTAINERD_VERSION_STRING[2]}
      echo "${CONTAINERD_VERSION}"

      if [ -n "$CONTAINERD_VERSION" ] && version_lte "1.5.0" "$CONTAINERD_VERSION" && version_lt "$CONTAINERD_VERSION" "2.0"; then
          echo "CONTAINERD_VERSION is not empty and within the range [1.5.0, 2.0)."
          echo "Patching /etc/eks/containerd/containerd-config.toml"
          mkdir -p /etc/eks/containerd

          cat > /etc/eks/containerd/containerd-config.toml << EOF

      root = "/var/lib/containerd"
      state = "/run/containerd"

      [grpc]
      address = "/run/containerd/containerd.sock"

      [plugins.cri]
      sandbox_image = "SANDBOX_IMAGE"

      [plugins.cri.registry]
      config_path = "/etc/containerd/certs.d:/etc/docker/certs.d"

      [plugins.cri.containerd]
      default_runtime_name = "nvidia"

      [plugins.cri.containerd.runtimes.nvidia]
      privileged_without_host_devices = false
      runtime_engine = ""
      runtime_root = ""
      runtime_type = "io.containerd.runtime.v1.linux"

      [plugins.cri.containerd.runtimes.nvidia.options]
      Runtime = "/etc/docker-runtimes.d/nvidia"
      SystemdCgroup = true

      EOF

      else
          echo "CONTAINERD_VERSION is empty or not within the specified range."
      fi

      rmmod nvidia_drm
      rmmod nvidia_modeset
      rmmod nvidia_uvm
      rmmod nvidia
      echo "Writing NVreg_EnableGpuFirmware=0 to /etc/modprobe.d/nvidia.conf"
      echo "options nvidia NVreg_EnableGpuFirmware=0" | tee --append /etc/modprobe.d/nvidia.conf
      echo "Writing NVreg_EnableGpuFirmware=0 to /etc/modprobe.d/nvidia-gsp.conf"
      echo "options nvidia NVreg_EnableGpuFirmware=0" | tee --append /etc/modprobe.d/nvidia-gsp.conf
      echo "Running dracut"
      dracut -f

  ## Default Inferentia Node Template Config
  inferentiaDefaultNodeTemplate:
    ## @param karpenter.inferentiaDefaultNodeTemplate.rootVolumeSize Size for the root volume attached to node
    rootVolumeSize: 100Gi
    ## @param karpenter.inferentiaDefaultNodeTemplate.extraTags Additional tags for the node template.
    extraTags: {}
    ## @param karpenter.inferentiaDefaultNodeTemplate.amiFamily AMI family to use for node template
    amiFamily: "AL2"
    ## @skip karpenter.inferentiaDefaultNodeTemplate.userData
    # Set this to "" to disable this injection
    userData: ""

  ## provisioner for inferentia workloads
  inferentiaProvisionerSpec:
    ## @param karpenter.inferentiaProvisionerSpec.enabled Enable inferentia provisioner for inferentia nodes
    ##
    enabled: false

    ## @param karpenter.inferentiaProvisionerSpec.consolidation.enabled Enable consolidation for inferentia provisioner
    ##
    consolidation:
      enabled: false

    ## @param karpenter.inferentiaProvisionerSpec.ttlSecondsAfterEmpty Seconds after which node should be deleted once it is empty. Either one of consolidation or ttlSecondsAfterEmpty should be used
    ## 
    ttlSecondsAfterEmpty: 300

    ## @param karpenter.inferentiaProvisionerSpec.capacityTypes Capacity types for inferentia provisioner
    ##    
    capacityTypes:
    - spot
    - on-demand
    ## @param karpenter.inferentiaProvisionerSpec.zones Zones to launch instances for inferentia provisioner
    ## 
    zones: []
    ## @param karpenter.inferentiaProvisionerSpec.instanceFamilies Instance families to launch instances for inferentia provisioner
    ## 
    instanceFamilies:
    - inf1
    - inf2
    ## @param karpenter.inferentiaProvisionerSpec.instanceSizes.notAllowed Instance Sizes that are not allowed to launch instances for inferentia provisioner
    ##
    instanceSizes:
      notAllowed:
      - 48xlarge
    ## @param karpenter.inferentiaProvisionerSpec.providerRefName Name of AWS node template to be used for inferentia provisioner
    ##
    providerRefName: inferentia-default
