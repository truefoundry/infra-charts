## @section Configuration for the cluster type flags.
##
## @param clusterType.awsEks Flag indicating AWS EKS cluster type.
##
## @param clusterType.gcpGkeStandard Flag indicating GCP GKE Standard cluster type.
##
## @param clusterType.gcpGkeAutopilot Flag indicating GCP GKE Autopilot cluster type.
##
## @param clusterType.azureAks Flag indicating Azure AKS cluster type.
##
## @param clusterType.civoTalos Flag indicating Civo Talos cluster type.
##
clusterType:
  awsEks: false
  gcpGkeStandard: false
  gcpGkeAutopilot: false
  azureAks: false
  civoTalos: false

## @section aws-eks-gpu-operator Configuration for the AWS EKS GPU Operator. This section will only be used when clusterType.awsEks is set to true.
##
aws-eks-gpu-operator:
  ## Operator configuration.
  ##
  operator:
    ## Resource configuration for operator requests and limits.
    ##
    ## @param aws-eks-gpu-operator.operator.resources.requests.cpu CPU request for the operator.
    ##
    ## @param aws-eks-gpu-operator.operator.resources.requests.memory Memory request for the operator.
    ##
    ## @param aws-eks-gpu-operator.operator.resources.limits.cpu CPU limit for the operator.
    ##
    ## @param aws-eks-gpu-operator.operator.resources.limits.memory Memory limit for the operator.
    ##
    resources:
      requests:
        cpu: 10m
        memory: 200Mi
      limits:
        cpu: 50m
        memory: 300Mi
  
  ## Toolkit configuration.
  ##
  ## @param aws-eks-gpu-operator.toolkit.version Version of the toolkit.
  ## @skip aws-eks-gpu-operator.toolkit.env
  toolkit:
    version: v1.13.5-centos7
    env:
      - name: ACCEPT_NVIDIA_VISIBLE_DEVICES_ENVVAR_WHEN_UNPRIVILEGED
        value: 'false'
      - name: ACCEPT_NVIDIA_VISIBLE_DEVICES_AS_VOLUME_MOUNTS
        value: 'true'
  
  ## Device Plugin configuration.
  ##
  ## @skip aws-eks-gpu-operator.devicePlugin.env
  devicePlugin:
    env:
      - name: PASS_DEVICE_SPECS
        value: 'true'
      - name: DEVICE_LIST_STRATEGY
        value: volume-mounts
      - name: DEVICE_ID_STRATEGY
        value: index
  
  ## Node Feature Discovery configuration.
  ##
  node-feature-discovery:
    master:
      ##
      ## @param aws-eks-gpu-operator.node-feature-discovery.master.resources.requests.cpu CPU request for master node feature discovery.
      ## @param aws-eks-gpu-operator.node-feature-discovery.master.resources.requests.memory Memory request for master node feature discovery.
      resources:
        requests:
          cpu: 10m
          memory: 400Mi
    worker:
      ##
      ## @param aws-eks-gpu-operator.node-feature-discovery.worker.resources.requests.cpu CPU request for worker node feature discovery.
      ## @param aws-eks-gpu-operator.node-feature-discovery.worker.resources.requests.memory Memory request for worker node feature discovery.
      ## @param aws-eks-gpu-operator.node-feature-discovery.worker.resources.limits.cpu CPU limit for worker node feature discovery.
      ## @param aws-eks-gpu-operator.node-feature-discovery.worker.resources.limits.memory Memory limit for worker node feature discovery.
      resources:
        requests:
          cpu: 10m
          memory: 100Mi
        limits:
          cpu: 50m
          memory: 300Mi
      affinity:
        ## @skip aws-eks-gpu-operator.node-feature-discovery.worker.affinity.nodeAffinity
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - p2.xlarge
                      - p2.8xlarge
                      - p2.16xlarge
                      - p3.2xlarge
                      - p3.8xlarge
                      - p3.16xlarge
                      - p3dn.24xlarge
                      - p4d.24xlarge
                      - p4de.24xlarge
                      - p5.48xlarge
                      - g4dn.xlarge
                      - g4dn.2xlarge
                      - g4dn.4xlarge
                      - g4dn.8xlarge
                      - g4dn.16xlarge
                      - g4dn.12xlarge
                      - g4dn.metal
                      - g4dn.xlarge
                      - g5.xlarge
                      - g5.2xlarge
                      - g5.4xlarge
                      - g5.8xlarge
                      - g5.16xlarge
                      - g5.12xlarge
                      - g5.24xlarge
                      - g5.48xlarge
    gc:
      ##
      ## @param aws-eks-gpu-operator.node-feature-discovery.gc.enable Enable node feature discovery garbage collector.
      ## @skip aws-eks-gpu-operator.node-feature-discovery.gc.rbac.create
      ## @skip aws-eks-gpu-operator.node-feature-discovery.gc.serviceAccount.create
      ## @param aws-eks-gpu-operator.node-feature-discovery.gc.interval Interval between two garbage collection runs.
      ## @param aws-eks-gpu-operator.node-feature-discovery.gc.resources.requests.cpu CPU request for node feature discovery garbage collector.
      ## @param aws-eks-gpu-operator.node-feature-discovery.gc.resources.requests.memory Memory request for node feature discovery garbage collector.
      enable: true
      serviceAccount:
        create: true
      rbac:
        create: true
      interval: 30m
      resources:
        requests:
          cpu: 10m
          memory: 100Mi
      affinity:
        ## @skip aws-eks-gpu-operator.node-feature-discovery.gc.affinity.nodeAffinity
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: NotIn
                    values:
                      - p2.xlarge
                      - p2.8xlarge
                      - p2.16xlarge
                      - p3.2xlarge
                      - p3.8xlarge
                      - p3.16xlarge
                      - p3dn.24xlarge
                      - p4d.24xlarge
                      - p4de.24xlarge
                      - p5.48xlarge
                      - g4dn.xlarge
                      - g4dn.2xlarge
                      - g4dn.4xlarge
                      - g4dn.8xlarge
                      - g4dn.16xlarge
                      - g4dn.12xlarge
                      - g4dn.metal
                      - g4dn.xlarge
                      - g5.xlarge
                      - g5.2xlarge
                      - g5.4xlarge
                      - g5.8xlarge
                      - g5.16xlarge
                      - g5.12xlarge
                      - g5.24xlarge
                      - g5.48xlarge
      tolerations:
        ## @skip aws-eks-gpu-operator.node-feature-discovery.gc.tolerations[0]
        - operator: Exists

  ## Daemonsets configuration
  ##
  ## @param aws-eks-gpu-operator.daemonsets.updateStrategy Update Strategy for Daemonsets - one of ["OnDelete", "RollingUpdate"]
  ##
  daemonsets:
    # This is set to OnDelete to protect against pod failures in case device plugin is unavailable during a kubelet restart
    # The downside being Daemonset will not be updated until it is manually deleted,
    # which is mostly okay for gpu case - effect of toolkit, device plugin daemonsets are limited to the node they run on.
    # If needed, older nodes can be drained to force a newer versions on a newer nodes
    # This will be changed to "RollingUpdate" when newer kubelet versions with allocation issue fix become the norm
    # We would also like to use `daemonsets.rollingUpdate.maxSurge: 1` which is not supported yet
    updateStrategy: "OnDelete"
  
  ## Validator configuration.
  ##
  validator:
    plugin:
      env:
        ## @param aws-eks-gpu-operator.validator.plugin.env[0].name Name of the Evironment Variable for the Validator Plugin
        ## @param aws-eks-gpu-operator.validator.plugin.env[0].value Value of the Evironment Variable for the Validator Plugin
        - name: WITH_WORKLOAD
          value: "false"
  
  ## DCGM Exporter configuration.
  ##
  ## @param aws-eks-gpu-operator.dcgmExporter.version Version of the DCGM Exporter.
  ##
  ## @param aws-eks-gpu-operator.dcgmExporter.resources.requests.cpu CPU request for the DCGM Exporter.
  ## @param aws-eks-gpu-operator.dcgmExporter.resources.requests.memory Memory request for the DCGM Exporter.
  ## @param aws-eks-gpu-operator.dcgmExporter.resources.limits.cpu CPU limit for the DCGM Exporter.
  ## @param aws-eks-gpu-operator.dcgmExporter.resources.limits.memory Memory limit for the DCGM Exporter.
  ##
  ## @param aws-eks-gpu-operator.dcgmExporter.args Arguments for the DCGM Exporter.
  ##
  ## @param aws-eks-gpu-operator.dcgmExporter.serviceMonitor.enabled Enable or disable ServiceMonitor for DCGM Exporter.
  ##
  dcgmExporter:
    version: 3.1.7-3.1.4-ubuntu20.04
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
      limits:
        cpu: 100m
        memory: 400Mi
    args: ["-c", "5000"]
    serviceMonitor:
      enabled: false

## @section gcp-gke-standard-dcgm-exporter Configuration for the GCP GKE Standard DCGM Exporter. This section will only be used when clusterType.gcpGkeStandard is set to true.
##
gcp-gke-standard-dcgm-exporter:
  ## Docker image tag for the DCGM Exporter.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.image.tag Docker image tag for the DCGM Exporter.
  ##
  image:
    tag: 3.1.7-3.1.4-ubuntu20.04
  ## Arguments to pass to the DCGM Exporter.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.arguments Arguments for the DCGM Exporter.
  ##
  arguments:
    [
      "-c",
      '"5000"',
      "-f",
      "/etc/dcgm-exporter/dcp-metrics-included.csv",
      "--kubernetes-gpu-id-type",
      "device-name",
    ]
  ## Resource configuration for DCGM Exporter requests and limits.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.resources.requests.cpu CPU request for the DCGM Exporter.
  ## @param gcp-gke-standard-dcgm-exporter.resources.requests.memory Memory request for the DCGM Exporter.
  ## @param gcp-gke-standard-dcgm-exporter.resources.limits.cpu CPU limit for the DCGM Exporter.
  ## @param gcp-gke-standard-dcgm-exporter.resources.limits.memory Memory limit for the DCGM Exporter.
  ##
  resources:
    requests:
      cpu: 10m
      memory: 300Mi
    limits:
      cpu: 100m
      memory: 400Mi
  ## Namespace override for the DCGM Exporter.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.namespaceOverride Namespace override for the DCGM Exporter.
  ##
  namespaceOverride: tfy-gpu-operator
  ## ServiceMonitor configuration for Prometheus monitoring.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.serviceMonitor.enabled Enable or disable ServiceMonitor for DCGM Exporter.
  ##
  serviceMonitor:
    enabled: false
  ## Node affinity configuration for worker nodes with GKE accelerators.
  ##
  affinity:
    ## @skip gcp-gke-standard-dcgm-exporter.affinity.nodeAffinity
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
  ## @param gcp-gke-standard-dcgm-exporter.tolerations[0].operator Toleration configuration for worker nodes.
  ##
  tolerations:
    - operator: "Exists"
  ## @param gcp-gke-standard-dcgm-exporter.mapPodsMetrics Enable mapping of pod metrics.
  ##
  mapPodsMetrics: true
  ## Security context configuration.
  ##
  ## @param gcp-gke-standard-dcgm-exporter.securityContext.privileged Set the container to privileged mode.
  ##
  securityContext:
    privileged: true
  ## @param gcp-gke-standard-dcgm-exporter.priorityClassName Priority class name for the DCGM Exporter.
  ##
  priorityClassName: ""
  ## Additional environment variables for the DCGM Exporter.
  ##
  extraEnv:
    ## @param gcp-gke-standard-dcgm-exporter.extraEnv[0].name Name for the additional environment variable for the DCGM Exporter.
    ## @param gcp-gke-standard-dcgm-exporter.extraEnv[0].value Value for the additional environment variable for the DCGM Exporter.
    - name: NVIDIA_INSTALL_DIR_HOST
      value: /home/kubernetes/bin/nvidia
    ## @skip gcp-gke-standard-dcgm-exporter.extraEnv[1]
    - name: NVIDIA_INSTALL_DIR_CONTAINER
      value: /usr/local/nvidia
    ## @skip gcp-gke-standard-dcgm-exporter.extraEnv[2]
    - name: DCGM_EXPORTER_COLLECTORS
      value: "/etc/dcgm-exporter/dcp-metrics-included.csv"
  ## Additional host volumes for the DCGM Exporter.
  ##
  extraHostVolumes:
    ## @param gcp-gke-standard-dcgm-exporter.extraHostVolumes[0].name Name for the additional host volume for the DCGM Exporter.
    ## @param gcp-gke-standard-dcgm-exporter.extraHostVolumes[0].hostPath Host Path for the additional host volume for the DCGM Exporter.
    - name: dev
      hostPath: "/dev"
    ## @skip gcp-gke-standard-dcgm-exporter.extraHostVolumes[1]
    - name: nvidia-install-dir-host
      hostPath: "/home/kubernetes/bin/nvidia"
    ## @skip gcp-gke-standard-dcgm-exporter.extraHostVolumes[2]
    - name: nvidia-config
      hostPath: "/etc/nvidia"
  ## Additional volume mounts for the DCGM Exporter.
  ##
  extraVolumeMounts:
    ## @param gcp-gke-standard-dcgm-exporter.extraVolumeMounts[0].name Name for the additional volume mounts for the DCGM Exporter.
    ## @param gcp-gke-standard-dcgm-exporter.extraVolumeMounts[0].mountPath Mount Path for the additional volume mounts for the DCGM Exporter.
    - name: dev
      mountPath: /dev
    ## @skip gcp-gke-standard-dcgm-exporter.extraVolumeMounts[1]
    - name: nvidia-install-dir-host
      mountPath: /usr/local/nvidia
    ## @skip gcp-gke-standard-dcgm-exporter.extraVolumeMounts[2]
    - name: nvidia-config
      mountPath: /etc/nvidia

## @section azure-aks-dcgm-exporter Configuration for the Azure AKS DCGM Exporter. This section will only be used when clusterType.azureAks is set to true.
##
azure-aks-dcgm-exporter:
  ## Docker image tag for the DCGM Exporter.
  ##
  ## @param azure-aks-dcgm-exporter.image.tag Docker image tag for the DCGM Exporter.
  ##
  image:
    tag: 3.1.7-3.1.4-ubuntu20.04
  ## Arguments to pass to the DCGM Exporter.
  ##
  ## @param azure-aks-dcgm-exporter.arguments Arguments for the DCGM Exporter.
  ##
  arguments:
    ["-c", '"5000"', "-f", "/etc/dcgm-exporter/dcp-metrics-included.csv"]
  ## Resource configuration for DCGM Exporter requests and limits.
  ##
  ## @param azure-aks-dcgm-exporter.resources.requests.cpu CPU request for the DCGM Exporter.
  ## @param azure-aks-dcgm-exporter.resources.requests.memory Memory request for the DCGM Exporter.
  ## @param azure-aks-dcgm-exporter.resources.limits.cpu CPU limit for the DCGM Exporter.
  ## @param azure-aks-dcgm-exporter.resources.limits.memory Memory limit for the DCGM Exporter.
  ##
  resources:
    requests:
      cpu: 10m
      memory: 300Mi
    limits:
      cpu: 100m
      memory: 400Mi
  ## Namespace override for the DCGM Exporter.
  ##
  ## @param azure-aks-dcgm-exporter.namespaceOverride Namespace override for the DCGM Exporter.
  ##
  namespaceOverride: tfy-gpu-operator
  ## ServiceMonitor configuration for Prometheus monitoring.
  ##
  ## @param azure-aks-dcgm-exporter.serviceMonitor.enabled Enable or disable ServiceMonitor for DCGM Exporter.
  ##
  serviceMonitor:
    enabled: false
  ## Node affinity configuration for worker nodes with NVIDIA accelerators.
  ##
  affinity:
    ## @skip azure-aks-dcgm-exporter.affinity.nodeAffinity
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: kubernetes.azure.com/accelerator
                operator: In
                values:
                  - nvidia
  ## Toleration configuration for worker nodes.
  ##
  tolerations:
    ## @skip azure-aks-dcgm-exporter.tolerations[0].operator
    - operator: "Exists"
  ## Enable mapping of pod metrics.
  ##
  ## @param azure-aks-dcgm-exporter.mapPodsMetrics Enable or disable mapping of pod metrics.
  ##
  mapPodsMetrics: true
  ## Security context configuration.
  ##
  ## @param azure-aks-dcgm-exporter.securityContext.privileged Set the container to privileged mode.
  ##
  securityContext:
    privileged: true
  ## Priority class name for the DCGM Exporter.
  ##
  ## @param azure-aks-dcgm-exporter.priorityClassName Priority class name for the DCGM Exporter.
  ##
  priorityClassName: ""
  ## Additional environment variables for the DCGM Exporter.
  ##
  extraEnv:
    ## @param azure-aks-dcgm-exporter.extraEnv[0].name Name for the additional environment variables for the DCGM Exporter.
    ## @param azure-aks-dcgm-exporter.extraEnv[0].value Value for the additional environment variables for the DCGM Exporter.
    - name: NVIDIA_INSTALL_DIR_HOST
      value: /home/kubernetes/bin/nvidia
    ## @skip azure-aks-dcgm-exporter.extraEnv[1]
    - name: NVIDIA_INSTALL_DIR_CONTAINER
      value: /usr/local/nvidia
    ## @skip azure-aks-dcgm-exporter.extraEnv[2]
    - name: DCGM_EXPORTER_COLLECTORS
      value: "/etc/dcgm-exporter/dcp-metrics-included.csv"
  ## Additional host volumes for the DCGM Exporter.
  ##
  extraHostVolumes:
    ## @param azure-aks-dcgm-exporter.extraHostVolumes[0].name Name for the additional host volumes for the DCGM Exporter.
    ## @param azure-aks-dcgm-exporter.extraHostVolumes[0].hostPath Host Path for the additional host volumes for the DCGM Exporter.
    - name: dev
      hostPath: "/dev"
    ## @skip azure-aks-dcgm-exporter.extraHostVolumes[1]
    - name: nvidia-install-dir-host
      hostPath: "/home/kubernetes/bin/nvidia"
    ## @skip azure-aks-dcgm-exporter.extraHostVolumes[2]
    - name: nvidia-config
      hostPath: "/etc/nvidia"
  ## Additional volume mounts for the DCGM Exporter.
  ##
  extraVolumeMounts:
    ## @param azure-aks-dcgm-exporter.extraVolumeMounts[0].name Name for the additional volume mounts for the DCGM Exporter.
    ## @param azure-aks-dcgm-exporter.extraVolumeMounts[0].mountPath Mount Path for the additional volume mounts for the DCGM Exporter.
    - name: dev
      mountPath: /dev
    ## @skip azure-aks-dcgm-exporter.extraVolumeMounts[1]
    - name: nvidia-install-dir-host
      mountPath: /usr/local/nvidia
    ## @skip azure-aks-dcgm-exporter.extraVolumeMounts[2]
    - name: nvidia-config
      mountPath: /etc/nvidia


## @section civo-talos-nvidia-device-plugin Configuration for the Civo Talos Nvidia Device Plugin. This section will only be used when clusterType.civoTalos is set to true.
##
civo-talos-nvidia-device-plugin:
  ## @param civo-talos-nvidia-device-plugin.namespaceOverride Namespace override for the Device Plugin.
  ##
  namespaceOverride: tfy-gpu-operator
  ## @param civo-talos-nvidia-device-plugin.updateStrategy.type Update Strategy for Daemonsets - one of ["OnDelete", "RollingUpdate"]
  ##
  updateStrategy:
    type: OnDelete
  ## @param civo-talos-nvidia-device-plugin.compatWithCPUManager Enable compatibility with CPUManager and PASS_DEVICE_SPECS
  ##
  compatWithCPUManager: true
  ## @param civo-talos-nvidia-device-plugin.deviceListStrategy How device plugin should list devices - one of ["volume-mounts", "envvar"]
  ##
  deviceListStrategy: volume-mounts
  ## @param civo-talos-nvidia-device-plugin.deviceIDStrategy How device plugin should pass device IDs - one of ["uuid", "index"]
  ##
  deviceIDStrategy: index
  ## @skip civo-talos-nvidia-device-plugin.securityContext.privileged
  ##
  securityContext:
    privileged: true
  ## @skip civo-talos-nvidia-device-plugin.affinity
  ##
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                  - g4g.kube.small
                  - g4g.kube.medium
                  - g4g.kube.large
                  - g4g.kube.xlarge
  ## @skip civo-talos-nvidia-device-plugin.tolerations
  ##
  tolerations:
    - operator: Exists


civo-talos-dcgm-exporter:
  ## @param civo-talos-dcgm-exporter.namespaceOverride Namespace override for the DCGM Exporter.
  ##
  namespaceOverride: tfy-gpu-operator
  ## @param civo-talos-dcgm-exporter.image.tag Image tag for the DCGM Exporter.
  ##
  image:
    tag: 3.2.6-3.1.9-ubuntu20.04
  ## @skip civo-talos-dcgm-exporter.extraEnv[0].name
  ## @skip civo-talos-dcgm-exporter.extraEnv[0].value
  ## 
  extraEnv:
    - name: DCGM_EXPORTER_COLLECTORS
      value: /etc/dcgm-exporter/dcp-metrics-included.csv
  ## @param civo-talos-dcgm-exporter.arguments Arguments for the DCGM Exporter.
  ##
  arguments:
    - '-c'
    - '"5000"'
    - '-f'
    - /etc/dcgm-exporter/dcp-metrics-included.csv
  ## Resource configuration for DCGM Exporter requests and limits.
  ##
  ## @param civo-talos-dcgm-exporter.resources.requests.cpu CPU request for the DCGM Exporter.
  ## @param civo-talos-dcgm-exporter.resources.requests.memory Memory request for the DCGM Exporter.
  ## @param civo-talos-dcgm-exporter.resources.limits.cpu CPU limit for the DCGM Exporter.
  ## @param civo-talos-dcgm-exporter.resources.limits.memory Memory limit for the DCGM Exporter.
  ##
  resources:
    limits:
      cpu: 100m
      memory: 400Mi
    requests:
      cpu: 10m
      memory: 300Mi
  ## Security context configuration.
  ##
  ## @param civo-talos-dcgm-exporter.securityContext.privileged Set the container to privileged mode.
  ##
  securityContext:
    privileged: true
  ## @skip civo-talos-dcgm-exporter.affinity
  ##
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                values:
                  - g4g.kube.small
                  - g4g.kube.medium
                  - g4g.kube.large
                  - g4g.kube.xlarge
                operator: In
  ## @skip civo-talos-dcgm-exporter.tolerations
  ##
  tolerations:
    - operator: Exists
  ## @param civo-talos-dcgm-exporter.mapPodsMetrics Enable mapping of pod metrics.
  ##
  mapPodsMetrics: true
  ## @param civo-talos-dcgm-exporter.serviceMonitor.enabled Enable or disable ServiceMonitor for DCGM Exporter.
  ##
  serviceMonitor:
    enabled: false
  ## @skip civo-talos-dcgm-exporter.extraHostVolumes[0].name
  ## @skip civo-talos-dcgm-exporter.extraHostVolumes[0].hostPath
  ##
  extraHostVolumes:
    - name: dev
      hostPath: /dev
  ## @skip civo-talos-dcgm-exporter.extraVolumeMounts[0].name
  ## @skip civo-talos-dcgm-exporter.extraVolumeMounts[0].mountPath
  ##
  extraVolumeMounts:
    - name: dev
      mountPath: /dev



