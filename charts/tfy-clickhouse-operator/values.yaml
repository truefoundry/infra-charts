## @section altinity-clickhouse-operator
altinity-clickhouse-operator:
  operator:
    image:
      repository: altinity/clickhouse-operator
      tag: ''
      pullPolicy: IfNotPresent
    containerSecurityContext: {}
    resources: {}
    env: []
  metrics:
    enabled: true
    image:
      repository: altinity/metrics-exporter
      tag: ''
      pullPolicy: IfNotPresent
    containerSecurityContext: {}
    resources: {}
    env: []
  imagePullSecrets: []
  podAnnotations:
    prometheus.io/port: '8888'
    prometheus.io/scrape: 'true'
    clickhouse-operator-metrics/port: '9999'
    clickhouse-operator-metrics/scrape: 'true'
  nameOverride: ''
  fullnameOverride: ''
  serviceAccount:
    create: true
    annotations: {}
    name: null
  rbac:
    create: true
  secret:
    create: true
    username: clickhouse_operator
    password: clickhouse_operator_password
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  serviceMonitor:
    enabled: false
    additionalLabels: {}
  configs:
    confdFiles: null
    configdFiles:
      01-clickhouse-01-listen.xml: |
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
            <!-- Listen wildcard address to allow accepting connections from other containers and host network. -->
            <listen_host>::</listen_host>
            <listen_host>0.0.0.0</listen_host>
            <listen_try>1</listen_try>
        </yandex>
      01-clickhouse-02-logger.xml: |
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
            <logger>
                <!-- Possible levels: https://github.com/pocoproject/poco/blob/devel/Foundation/include/Poco/Logger.h#L439 -->
                <level>debug</level>
                <log>/var/log/clickhouse-server/clickhouse-server.log</log>
                <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
                <size>1000M</size>
                <count>10</count>
                <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->
                <console>1</console>
            </logger>
        </yandex>
      01-clickhouse-03-query_log.xml: |
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
            <query_log replace="1">
                <database>system</database>
                <table>query_log</table>
                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            </query_log>
            <query_thread_log remove="1"/>
        </yandex>
      01-clickhouse-04-part_log.xml: |
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
            <part_log replace="1">
                <database>system</database>
                <table>part_log</table>
                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            </part_log>
        </yandex>
      01-clickhouse-05-trace_log.xml: |-
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
            <trace_log replace="1">
                <database>system</database>
                <table>trace_log</table>
                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            </trace_log>
        </yandex>
    files:
      config.yaml:
        watch:
          namespaces: []
        clickhouse:
          configuration:
            file:
              path:
                common: config.d
                host: conf.d
                user: users.d
            user:
              default:
                profile: default
                quota: default
                networksIP:
                  - '::1'
                  - 127.0.0.1
                password: default
            network:
              hostRegexpTemplate: >-
                (chi-{chi}-[^.]+\d+-\d+|clickhouse\-{chi})\.{namespace}\.svc\.cluster\.local$
          configurationRestartPolicy:
            rules:
              - version: '*'
                rules:
                  - settings/*: 'yes'
                  - settings/dictionaries_config: 'no'
                  - settings/logger: 'no'
                  - settings/macros/*: 'no'
                  - settings/max_server_memory_*: 'no'
                  - settings/max_*_to_drop: 'no'
                  - settings/max_concurrent_queries: 'no'
                  - settings/models_config: 'no'
                  - settings/user_defined_executable_functions_config: 'no'
                  - zookeeper/*: 'yes'
                  - files/*.xml: 'yes'
                  - files/config.d/*.xml: 'yes'
                  - files/config.d/*dict*.xml: 'no'
                  - profiles/default/background_*_pool_size: 'yes'
                  - profiles/default/max_*_for_server: 'yes'
              - version: 21.*
                rules:
                  - settings/logger: 'yes'
          access:
            scheme: auto
            username: ''
            password: ''
            rootCA: ''
            secret:
              namespace: ''
              name: '{{ include "altinity-clickhouse-operator.fullname" . }}'
            port: 8123
            timeouts:
              connect: 1
              query: 4
          metrics:
            timeouts:
              collect: 9
        template:
          chi:
            policy: ApplyOnNextReconcile
            path: templates.d
        reconcile:
          runtime:
            reconcileCHIsThreadsNumber: 10
            reconcileShardsThreadsNumber: 5
            reconcileShardsMaxConcurrencyPercent: 50
          statefulSet:
            create:
              onFailure: ignore
            update:
              timeout: 300
              pollInterval: 5
              onFailure: abort
          host:
            wait:
              exclude: true
              queries: true
              include: false
        annotation:
          include: []
          exclude: []
        label:
          include: []
          exclude: []
          appendScope: 'no'
        statefulSet:
          revisionHistoryLimit: 0
        pod:
          terminationGracePeriod: 30
        logger:
          logtostderr: 'true'
          alsologtostderr: 'false'
          v: '1'
          stderrthreshold: ''
          vmodule: ''
          log_backtrace_at: ''
    templatesdFiles:
      001-templates.json.example: |
        {
          "apiVersion": "clickhouse.altinity.com/v1",
          "kind": "ClickHouseInstallationTemplate",
          "metadata": {
            "name": "01-default-volumeclaimtemplate"
          },
          "spec": {
            "templates": {
              "volumeClaimTemplates": [
                {
                  "name": "chi-default-volume-claim-template",
                  "spec": {
                    "accessModes": [
                      "ReadWriteOnce"
                    ],
                    "resources": {
                      "requests": {
                        "storage": "2Gi"
                      }
                    }
                  }
                }
              ],
              "podTemplates": [
                {
                  "name": "chi-default-oneperhost-pod-template",
                  "distribution": "OnePerHost",
                  "spec": {
                    "containers" : [
                      {
                        "name": "clickhouse",
                        "image": "clickhouse/clickhouse-server:23.8",
                        "ports": [
                          {
                            "name": "http",
                            "containerPort": 8123
                          },
                          {
                            "name": "client",
                            "containerPort": 9000
                          },
                          {
                            "name": "interserver",
                            "containerPort": 9009
                          }
                        ]
                      }
                    ]
                  }
                }
              ]
            }
          }
        }
      default-pod-template.yaml.example: |
        apiVersion: "clickhouse.altinity.com/v1"
        kind: "ClickHouseInstallationTemplate"
        metadata:
          name: "default-oneperhost-pod-template"
        spec:
          templates:
            podTemplates:
              - name: default-oneperhost-pod-template
                distribution: "OnePerHost"
      default-storage-template.yaml.example: |
        apiVersion: "clickhouse.altinity.com/v1"
        kind: "ClickHouseInstallationTemplate"
        metadata:
          name: "default-storage-template-2Gi"
        spec:
          templates:
            volumeClaimTemplates:
              - name: default-storage-template-2Gi
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 2Gi
      readme: >-
        Templates in this folder are packaged with an operator and available via
        'useTemplate'
    usersdFiles:
      01-clickhouse-operator-profile.xml: |
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <!--
        #
        # Template parameters available:
        #
        -->
        <yandex>
            <!-- clickhouse-operator user is generated by the operator based on config.yaml in runtime -->
            <profiles>
                <clickhouse_operator>
                    <log_queries>0</log_queries>
                    <skip_unavailable_shards>1</skip_unavailable_shards>
                    <http_connection_timeout>10</http_connection_timeout>
                    <max_concurrent_queries_for_all_users>0</max_concurrent_queries_for_all_users>
                    <os_thread_priority>0</os_thread_priority>
                </clickhouse_operator>
            </profiles>
        </yandex>
      02-clickhouse-default-profile.xml: |-
        <!-- IMPORTANT -->
        <!-- This file is auto-generated -->
        <!-- Do not edit this file - all changes would be lost -->
        <!-- Edit appropriate template in the following folder: -->
        <!-- deploy/builder/templates-config -->
        <!-- IMPORTANT -->
        <yandex>
          <profiles>
            <default>
              <os_thread_priority>2</os_thread_priority>
              <log_queries>1</log_queries>
              <connect_timeout_with_failover_ms>1000</connect_timeout_with_failover_ms>
              <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
              <parallel_view_processing>1</parallel_view_processing>
              <do_not_merge_across_partitions_select_final>1</do_not_merge_across_partitions_select_final>
              <load_balancing>nearest_hostname</load_balancing>
              <prefer_localhost_replica>0</prefer_localhost_replica>
              <!-- materialize_ttl_recalculate_only>1</materialize_ttl_recalculate_only> 21.10 and above -->
            </default>
          </profiles>
        </yandex>
  additionalResources: []
  dashboards:
    enabled: false
    additionalLabels:
      grafana_dashboard: ''
    annotations: {}
    grafana_folder: clickhouse

## @section zookeeper
zookeeper:
  enabled: true
  global:
    imageRegistry: ''
    imagePullSecrets: []
    storageClass: ''
    compatibility:
      openshift:
        adaptSecurityContext: disabled
  kubeVersion: ''
  nameOverride: ''
  fullnameOverride: ''
  clusterDomain: cluster.local
  extraDeploy: []
  commonLabels: {}
  commonAnnotations: {}
  namespaceOverride: ''
  diagnosticMode:
    enabled: false
    command:
      - sleep
    args:
      - infinity
  image:
    registry: docker.io
    repository: bitnami/zookeeper
    tag: 3.9.2-debian-12-r0
    digest: ''
    pullPolicy: IfNotPresent
    pullSecrets: []
    debug: false
  auth:
    client:
      enabled: false
      clientUser: ''
      clientPassword: ''
      serverUsers: ''
      serverPasswords: ''
      existingSecret: ''
    quorum:
      enabled: false
      learnerUser: ''
      learnerPassword: ''
      serverUsers: ''
      serverPasswords: ''
      existingSecret: ''
  tickTime: 2000
  initLimit: 10
  syncLimit: 5
  preAllocSize: 65536
  snapCount: 100000
  maxClientCnxns: 60
  maxSessionTimeout: 40000
  heapSize: 1024
  fourlwCommandsWhitelist: 'srvr, mntr, ruok'
  minServerId: 1
  listenOnAllIPs: false
  autopurge:
    snapRetainCount: 10
    purgeInterval: 1
  logLevel: ERROR
  jvmFlags: ''
  dataLogDir: ''
  configuration: ''
  existingConfigmap: ''
  extraEnvVars: []
  extraEnvVarsCM: ''
  extraEnvVarsSecret: ''
  command:
    - /scripts/setup.sh
  args: []
  replicaCount: 1
  containerPorts:
    client: 2181
    tls: 3181
    follower: 2888
    election: 3888
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
    probeCommandTimeout: 2
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
    probeCommandTimeout: 2
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  customLivenessProbe: {}
  customReadinessProbe: {}
  customStartupProbe: {}
  lifecycleHooks: {}
  resourcesPreset: none
  resources: {}
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  containerSecurityContext:
    enabled: true
    seLinuxOptions: null
    runAsUser: 1001
    runAsGroup: 0
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: false
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault
  automountServiceAccountToken: false
  hostAliases: []
  podLabels: {}
  podAnnotations: {}
  podAffinityPreset: ''
  podAntiAffinityPreset: soft
  nodeAffinityPreset:
    type: ''
    key: ''
    values: []
  affinity: {}
  nodeSelector: {}
  tolerations: []
  topologySpreadConstraints: []
  podManagementPolicy: Parallel
  priorityClassName: ''
  schedulerName: ''
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  extraVolumes: []
  extraVolumeMounts: []
  sidecars: []
  initContainers: []
  pdb:
    create: false
    minAvailable: ''
    maxUnavailable: 1
  enableServiceLinks: true
  dnsPolicy: ''
  dnsConfig: {}
  service:
    type: ClusterIP
    ports:
      client: 2181
      tls: 3181
      follower: 2888
      election: 3888
    nodePorts:
      client: ''
      tls: ''
    disableBaseClientPort: false
    sessionAffinity: None
    sessionAffinityConfig: {}
    clusterIP: ''
    loadBalancerIP: ''
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    annotations: {}
    extraPorts: []
    headless:
      publishNotReadyAddresses: true
      annotations: {}
      servicenameOverride: ''
  networkPolicy:
    enabled: true
    allowExternal: true
    allowExternalEgress: true
    extraIngress: []
    extraEgress: []
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  serviceAccount:
    create: true
    name: ''
    automountServiceAccountToken: false
    annotations: {}
  persistence:
    enabled: true
    existingClaim: ''
    storageClass: ''
    accessModes:
      - ReadWriteOnce
    size: 8Gi
    annotations: {}
    labels: {}
    selector: {}
    dataLogDir:
      size: 8Gi
      existingClaim: ''
      selector: {}
  volumePermissions:
    enabled: false
    image:
      registry: docker.io
      repository: bitnami/os-shell
      tag: 12-debian-12-r16
      digest: ''
      pullPolicy: IfNotPresent
      pullSecrets: []
    resourcesPreset: none
    resources: {}
    containerSecurityContext:
      enabled: true
      seLinuxOptions: null
      runAsUser: 0
  metrics:
    enabled: false
    containerPort: 9141
    service:
      type: ClusterIP
      port: 9141
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '{{ .Values.metrics.service.port }}'
        prometheus.io/path: /metrics
    serviceMonitor:
      enabled: false
      namespace: ''
      interval: ''
      scrapeTimeout: ''
      additionalLabels: {}
      selector: {}
      relabelings: []
      metricRelabelings: []
      honorLabels: false
      jobLabel: ''
    prometheusRule:
      enabled: false
      namespace: ''
      additionalLabels: {}
      rules: []
  tls:
    client:
      enabled: false
      auth: none
      autoGenerated: false
      existingSecret: ''
      existingSecretKeystoreKey: ''
      existingSecretTruststoreKey: ''
      keystorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.keystore.jks
      truststorePath: /opt/bitnami/zookeeper/config/certs/client/zookeeper.truststore.jks
      passwordsSecretName: ''
      passwordsSecretKeystoreKey: ''
      passwordsSecretTruststoreKey: ''
      keystorePassword: ''
      truststorePassword: ''
    quorum:
      enabled: false
      auth: none
      autoGenerated: false
      existingSecret: ''
      existingSecretKeystoreKey: ''
      existingSecretTruststoreKey: ''
      keystorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.keystore.jks
      truststorePath: /opt/bitnami/zookeeper/config/certs/quorum/zookeeper.truststore.jks
      passwordsSecretName: ''
      passwordsSecretKeystoreKey: ''
      passwordsSecretTruststoreKey: ''
      keystorePassword: ''
      truststorePassword: ''
    resourcesPreset: none
    resources: {}
